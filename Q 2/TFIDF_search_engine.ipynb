{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from NLTK_cleaning import clean \n",
    "\n",
    "def tf(term, text):\n",
    "    term_count = text.count(term)\n",
    "    total_words = len(text)\n",
    "    return term_count / total_words  \n",
    "\n",
    "def idf(term, df):\n",
    "    count = df[\"cleaned description\"].apply(lambda x: term in x if isinstance(x, str) else False).sum()\n",
    "    print(count)\n",
    "    return math.log((len(df))/(count))        \n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(query_tfidf, document_tfidf):\n",
    "    dot_product = np.dot(query_tfidf, document_tfidf)\n",
    "    norm_query = np.linalg.norm(query_tfidf)\n",
    "    norm_document = np.linalg.norm(document_tfidf)\n",
    "    if norm_query == 0 or norm_document == 0:\n",
    "        return 0.0 \n",
    "    cosine_similarity = dot_product / (norm_query * norm_document)\n",
    "    return cosine_similarity\n",
    "\n",
    "with open(r\"C:\\Users\\youse\\Desktop\\GitHub\\adm-hw3\\Databases\\saved_dictionary_tfidf.pkl\", 'rb') as f:\n",
    "    tfidf_dict = pickle.load(f)\n",
    "with open(r\"C:\\Users\\youse\\Desktop\\GitHub\\adm-hw3\\Databases\\saved_dictionary.pkl\", 'rb') as f:\n",
    "    inverted_index = pickle.load(f)\n",
    "\n",
    "vocab_path = r'C:\\Users\\youse\\Desktop\\GitHub\\adm-hw3\\Databases\\Vocabulary.csv'\n",
    "vocab = pd.read_csv(vocab_path)\n",
    "\n",
    "degrees = pd.read_csv(r\"C:\\Users\\youse\\Desktop\\GitHub\\adm-hw3\\Databases\\Parsed_database.csv\")\n",
    "degrees = degrees.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203    100203\n",
      "Name: term_id, dtype: int64\n",
      "204    100204\n",
      "Name: term_id, dtype: int64\n",
      "91    100091\n",
      "Name: term_id, dtype: int64\n",
      "217\n",
      "778\n",
      "780\n",
      "{4371, 5787, 29, 1314, 1315, 681, 4783, 4784, 50, 5690, 3389, 65, 5190, 5585, 1234, 5587, 3289, 1504, 3686, 4582, 1259, 1145, 5887}\n",
      "{'big': 1.1065391315565773, 'data': 0.6809294080106001, 'engineering': 0.6800736095088515}\n",
      "{4371: [0.09471960966286926, 0.05833343871767899, 0.05826017860428077], 5787: [0.04196438402785346, 0.025843928545807145, 0.025811471533542112], 29: [0.06255068562642309, 0.038522082172052156, 0.03847370285188353], 1314: [0.06139233959630414, 0.03780871027997712, 0.03776122687314494], 1315: [0.08500477790257496, 0.05235052192612216, 0.052284775670508384], 681: [0.07534514405000964, 0.04640159897997192, 0.0463433238897688], 4783: [0.07053587953617924, 0.0868795895795219, 0.04338523938616653], 4784: [0.07053587953617924, 0.0868795895795219, 0.04338523938616653], 50: [0.15069028810001928, 0.09280319795994384, 0.0926866477795376], 5690: [0.0436208728710582, 0.026864083619983742, 0.026830345409866143], 3389: [0.06630372676400847, 0.04083340710237529, 0.040782125022996545], 65: [0.060276115240007706, 0.07424255836795507, 0.03707465911181503], 5190: [0.08500477790257496, 0.05235052192612216, 0.052284775670508384], 5585: [0.03946650402619552, 0.024305599465699577, 0.02427507441845032], 1234: [0.07534514405000964, 0.04640159897997192, 0.0463433238897688], 5587: [0.040429101685371026, 0.049796837929725966, 0.024867149404266185], 3289: [0.07367080751556497, 0.04537045233597255, 0.045313472247773934], 1504: [0.06906638204584216, 0.04253479906497426, 0.04248138023228806], 3686: [0.06906638204584216, 0.04253479906497426, 0.04248138023228806], 4582: [0.05919975603929328, 0.03645839919854937, 0.03641261162767548], 1259: [0.06375358342693123, 0.03926289144459163, 0.03921358175288129], 1145: [0.06906638204584216, 0.04253479906497426, 0.04248138023228806], 5887: [0.04948039310746901, 0.030472691867444245, 0.030434421658952642]}\n"
     ]
    }
   ],
   "source": [
    "query = \"big data engineering \"\n",
    "\n",
    "match_list = []\n",
    "query = clean(query).lower().split(\" \")\n",
    "\n",
    "for lemma in query:\n",
    "    word_id = vocab[vocab['term'] == lemma]['term_id']\n",
    "    print(word_id)\n",
    "    try:\n",
    "        word_id = word_id.values[0]\n",
    "        matches = set(inverted_index[word_id]) \n",
    "        match_list.append(matches)\n",
    "    except:\n",
    "        print(f\"{lemma} not in dataset. It will not be included in search.\")\n",
    "        query.remove(lemma)\n",
    "\n",
    "result_id = set.intersection(*match_list)   \n",
    "all_results = pd.DataFrame(columns=[\"courseName\", \"universityName\", \"description\", \"url\"])\n",
    "\n",
    "query_tfidf={}\n",
    "tfidf_query_corpus = {}\n",
    "for word in query:\n",
    "    tf_query = tf(word, query)\n",
    "    idf_query = idf(word, degrees)\n",
    "    query_tfidf[word] = tf_query*idf_query\n",
    "\n",
    "\n",
    "for result in result_id:\n",
    "    doc = []\n",
    "    for word in query:\n",
    "        word_id = vocab[vocab['term'] == word]['term_id'].values[0]\n",
    "        doc.append([x[1] for x in tfidf_dict[word_id] if x[0]== result][0])\n",
    "    tfidf_query_corpus[result] = doc\n",
    "    \n",
    "print(query_tfidf)\n",
    "print(tfidf_query_corpus)      \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
